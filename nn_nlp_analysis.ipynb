{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I examine the neural network approaches. Using the Natural Language Processing in Action book, from Manning Publishing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes from book\n",
    "\n",
    "LSA: did not capture implied hidden meanings of words\n",
    "\n",
    "with word vectors: ble to decide things like is this an animal, place, etc, synonyms, \n",
    "word vectors are multidimensional vectors that capture the meaning of a word in different dimensions (e.g. animalness, placeness, etc), and then you can do math on it, e.g. vw(marie curie) - vw(science) + vw(music) (who is in music what marie curie is in physics\n",
    "\n",
    "example: searching for Marie Curie, combine meaning of woman, europe, physics, scientist, famous\n",
    "\n",
    "pg. 182, abstract example\n",
    "\n",
    "examples like this lead even beyond google, etc: who is to nuclear physics what louis pasteur is to germs\n",
    "\n",
    "can answer vgue questions and analogies\n",
    "\n",
    "word2vec: the google trained neural network released in 2013\n",
    "\n",
    "not needed to label anything, proximity of words is what matters, so it is unsupervised\n",
    "\n",
    "(in a way, labels are the words near other words in the dataset)\n",
    "\n",
    "in lsa, every word that occurs in same document will have impact on score, now, only close words will\n",
    "\n",
    "pg 187: very short example on how to use\n",
    "\n",
    "lsa is great for document classification, semantic search, and clustering, but not for semantic reasoning or working with short phrases\n",
    "\n",
    "word2vec: at time of publication, 40% accurate, went up after being trained on google news corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "two approaches on how to create word vectors: skip-gram approach and continuous bag-of-words (pg 191 for details)\n",
    "\n",
    "there are pre-trained ord-vector representations for corpora like wikipedia\n",
    "\n",
    "fastText: published by facebook\n",
    "\n",
    "skip-gram: divide text into n-grams, and ... pg 194, not entirely clear\n",
    "\n",
    "with softmax activation, calculate the probability of an output word being found as a surrounding word of an input word\n",
    "\n",
    "once training is done, weight matrix will be the embedding\n",
    "\n",
    "\n",
    "continuous b-o-w approach: instad of creating input - output tokens, multi-hot vector for all surrounding tokens to the center target token\n",
    "\n",
    "skip-gram approach works well with small corpora and rare terms, cobw is more accurate for frequent words, and faster to train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!stop words should not be ignored, they might carry meaning, plus word vectors are often used in generative models\n",
    "\n",
    "so they remain in, and to reduce emphasis, they are sampled in inverse proportion of their frequency\n",
    "\n",
    "small corpus: negative sampling rate of 5-20, large: can reduce to 2 to 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trying base example on pg 200, using the original pretrained thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "# this might make autocomplete faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = KeyedVectors.load_word2vec_format(\\\n",
    "    './word2vec_pretrained/GoogleNews-vectors-negative300.bin.gz', binary = True, limit = 1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('europe', 0.7222039103507996),\n",
       " ('spain', 0.701023519039154),\n",
       " ('european', 0.6962700486183167),\n",
       " ('german', 0.6810604929924011),\n",
       " ('italy', 0.6680153608322144),\n",
       " ('england', 0.66745924949646),\n",
       " ('usa', 0.6651221513748169),\n",
       " ('switzerland', 0.6604776978492737),\n",
       " ('sweden', 0.6577832698822021),\n",
       " ('india', 0.6428229808807373)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding synonyms\n",
    "word_vectors.most_similar(positive=['france', 'germany'], topn = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Beethoven'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding odd one outs\n",
    "word_vectors.doesnt_match(['Hitler', 'Churchill', 'Stalin', 'Beethoven'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7118192911148071)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# famous math operations\n",
    "word_vectors.most_similar(positive = ['king', 'woman'], negative = ['man'], topn = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gynecologist', 0.7093892097473145)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.most_similar(positive = ['doctor', 'woman'], negative = ['man'], topn = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mother', 0.8462507128715515)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.most_similar(positive = ['father', 'woman'], negative = ['man'], topn = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('art', 0.5378468036651611),\n",
       " ('artists', 0.5258477926254272),\n",
       " ('Pablo_Picasso', 0.49319028854370117),\n",
       " ('artist', 0.49227362871170044),\n",
       " ('artwork', 0.47473448514938354),\n",
       " ('painting', 0.46198058128356934),\n",
       " ('artist_Robert_Rauschenberg', 0.43100041151046753),\n",
       " ('artworks', 0.4306104779243469),\n",
       " ('painters', 0.43055960536003113),\n",
       " ('photography', 0.42579764127731323)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.most_similar(positive = ['music', 'Picasso'], negative = ['Beethoven'], topn = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Erroll_Garner', 0.5344928503036499),\n",
       " ('songs', 0.5321550965309143),\n",
       " ('Beethoven', 0.5134056806564331),\n",
       " ('Frampton_Comes_Alive', 0.5108814835548401),\n",
       " (\"Chico_O'Farrill\", 0.5059295892715454),\n",
       " ('Jimi_Hendrix', 0.5056772232055664),\n",
       " ('Mozart', 0.5042005777359009),\n",
       " ('Manu_Dibango', 0.49042925238609314),\n",
       " ('Chucho_Valdes', 0.4867725372314453),\n",
       " ('Mose_Allison', 0.4866839051246643)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.most_similar(positive = ['Picasso', 'music'], negative = ['art'], topn = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mao', 0.7007876634597778),\n",
       " ('Chairman_Mao', 0.6467739343643188),\n",
       " ('Mao_Zedong', 0.5951652526855469),\n",
       " ('Mao_Tse_tung', 0.5835192203521729),\n",
       " ('Deng_Xiaoping', 0.5821856260299683),\n",
       " ('Chairman_Mao_Zedong', 0.5699514150619507),\n",
       " ('Communist', 0.5632455348968506),\n",
       " ('Communist_Party_CCP', 0.5581366419792175),\n",
       " ('Hu_Yaobang', 0.5552926063537598),\n",
       " ('Great_Helmsman', 0.5500338077545166)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.most_similar(positive = ['China', 'Stalin'], negative = ['Russia'], topn = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hitler', 0.6709142923355103),\n",
       " ('Adolf_Hitler', 0.5992249250411987),\n",
       " ('Third_Reich', 0.5972428917884827),\n",
       " ('Nazi', 0.5926545858383179),\n",
       " ('Nazis', 0.5889713764190674),\n",
       " ('Hitler_Third_Reich', 0.5791662931442261),\n",
       " ('Hilter', 0.5716949701309204),\n",
       " ('Adolph_Hitler', 0.5711631774902344),\n",
       " ('Nazi_Germany', 0.5646259784698486),\n",
       " ('Fuehrer', 0.5622488856315613)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.most_similar(positive = ['Germany', 'Stalin'], negative = ['Russia'], topn = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Pétain', 0.608258843421936),\n",
       " ('Mitterand', 0.5562480688095093),\n",
       " ('Maurice_Papon', 0.5539685487747192),\n",
       " ('De_Gaulle', 0.5534417033195496),\n",
       " ('Petain', 0.5488604307174683),\n",
       " ('de_Gaulle', 0.5444628000259399),\n",
       " ('François_Mitterrand', 0.5440154075622559),\n",
       " ('Vichy', 0.5330964922904968),\n",
       " ('Francois_Mitterand', 0.5310631990432739),\n",
       " ('Hitler', 0.5308597087860107)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.most_similar(positive = ['France', 'Stalin'], negative = ['Russia'], topn = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Ceaucescu', 0.5413000583648682),\n",
       " ('Gyula', 0.5344285368919373),\n",
       " ('Hitler', 0.5297396183013916),\n",
       " ('Imre_Nagy', 0.5281765460968018),\n",
       " ('Ferenc', 0.5272859930992126),\n",
       " ('Mussolini', 0.5254130959510803),\n",
       " ('Miklós', 0.5238747596740723),\n",
       " ('László', 0.5185155868530273),\n",
       " ('Goebbels', 0.514951229095459),\n",
       " ('Sándor', 0.5110854506492615)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.most_similar(positive = ['Hungary', 'Stalin'], negative = ['Russia'], topn = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
